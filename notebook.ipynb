{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as client\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Book Assistant\",\n",
    "    instructions=\"You help users with their question on the files they upload.\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as client\n",
    "\n",
    "# assistant = client.beta.assistants.create(\n",
    "#    name=\"Book Assistant\",\n",
    "#    instructions=\"You help users with their question on the files they upload.\",\n",
    "#    model=\"gpt-4-1106-preview\",\n",
    "#    tools=[{\"type\": \"file_search\"}],\n",
    "#)\n",
    "assistant_id = \"asst_kjnv9pKth1asyF06vZFrGAWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_szLUojUKpLeU66zky1f1qrpR', created_at=1722843350, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I want you to help me with this file\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-rcldzVm3dcFTptUwk2U4MjKS', bytes=15801, created_at=1722843354, filename='chapter_one.txt', object='file', purpose='assistants', status='processed', status_details=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = client.files.create(\n",
    "    file=client.file_from_path(\"C:\\Python\\\\fullstack_gpt\\\\files\\chapter_one.txt\"), purpose=\"assistants\"\n",
    ")\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_qZ0RSzKnDAmCTFgcc3URsNcM', assistant_id=None, attachments=[Attachment(file_id='file-rcldzVm3dcFTptUwk2U4MjKS', tools=[AttachmentToolAssistantToolsFileSearchTypeOnly(type='file_search')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Please refer to the uploaded file for my question. '), type='text')], created_at=1722843364, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_szLUojUKpLeU66zky1f1qrpR')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"Please refer to the uploaded file for my question. \",\n",
    "  attachments=[{\n",
    "    \"file_id\": file.id,\n",
    "    \"tools\": [{\"type\": \"file_search\",}],}],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_21FFoiobdUUbQnTiS6avIzUX', assistant_id='asst_kjnv9pKth1asyF06vZFrGAWN', cancelled_at=None, completed_at=None, created_at=1722843406, expires_at=1722844006, failed_at=None, incomplete_details=None, instructions='You help users with their question on the files they upload.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_szLUojUKpLeU66zky1f1qrpR', tool_choice='auto', tools=[FileSearchTool(type='file_search', file_search=None)], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "    )\n",
    "\n",
    "\n",
    "def send_message(thread_id, content):\n",
    "    return client.beta.threads.messages.create(\n",
    "        thread_id=thread_id, role=\"user\", content=content\n",
    "    )\n",
    "\n",
    "\n",
    "def get_messages(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    for message in messages:\n",
    "        print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "        for annotation in message.content[0].text.annotations:\n",
    "            print(f\"Source: {annotation.file_citation}\")\n",
    "\n",
    "\n",
    "def get_tool_outputs(run_id, thread_id):\n",
    "    run = get_run(run_id, thread_id)\n",
    "    outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        action_id = action.id\n",
    "        function = action.function\n",
    "        print(f\"Calling function: {function.name} with arg {function.arguments}\")\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"output\": functions_map[function.name](json.loads(function.arguments)),\n",
    "                \"tool_call_id\": action_id,\n",
    "            }\n",
    "        )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def submit_tool_outputs(run_id, thread_id):\n",
    "    outpus = get_tool_outputs(run_id, thread_id)\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "        tool_outputs=outpus,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run(run.id, thread.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: I want you to help me with this file\n",
      "user: Please refer to the uploaded file for my question. \n",
      "assistant: It appears that your question wasn't included in your initial message, and since you've asked me to refer to the uploaded file, I'm not able to see any specific question or context. Could you please provide me with more details or clarify what aspect of the file you need assistance with? Once I have a better understanding of your question, I can provide you with the relevant information from the file.\n",
      "user: Who is Mr. Goldwin Smith?\n",
      "assistant: Mr. Goldwin Smith is mentioned in the context of his observation about Jane Austen's art. He has been quoted as saying that \"metaphor has been exhausted in depicting the perfection of it [Jane Austen's art], combined with the narrowness of her field,\" and he adds that one need not go beyond Austen's own comparison to the art of a miniature painter. This observation is used to emphasize the quality of Jane Austen's work and her craftsmanship despite the limited scope of her themes .\n"
     ]
    }
   ],
   "source": [
    "get_messages(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message(\n",
    "    thread.id,\n",
    "    \"Where does he work?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_z89xCprb7mdsw1JIyrEJdbCM', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Who is Mr. Goldwin Smith?'), type='text')], created_at=1722843381, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_szLUojUKpLeU66zky1f1qrpR')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_message(\n",
    "    thread.id,\n",
    "    \"Who is Mr. Goldwin Smith?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_KEY\"),\n",
    ")\n",
    "\n",
    "client = session.client(\"bedrock-runtime\", \"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Here is the translation:\\n\\n나는 아마존을 좋아해!', id='run-5305f0ab-f179-4754-8ff1-381a3a2f3193-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import BedrockChat\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = BedrockChat(\n",
    "    client=client,\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Translate this sentence from {lang_a} to {lang_b}: {sentence}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"lang_a\": \"English\",\n",
    "        \"lang_b\": \"Korean\",\n",
    "        \"sentence\": \"I love amazon!\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
